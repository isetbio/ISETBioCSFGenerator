Renaming
1) 't_neuralResponseComputeExternalPipeline' -> 't_neuralResponseComputeCustomizedPipeline'
2) 'rcePoissonNWay_OneStimPerTrial' -> 'rcePoissonNWay_OneStimulusPerTrial.m'

============================================================================================================================
Fixed bugs
1) t_modulatedGratingsSceneGeneration.m
Stimulus #5: the original stimulus was out of the display gamut.
To fix it, I reduced the 'conContrastModulation' to lower values (e.g., [0.1, 0.1, -0.1])
	DHB: Make it as high as you can within gamut.
	FH: Done.

2) there is a bug in t_NWay_OneStimPerTrial.m (can't run). The bug is it calls computeThresholdNWay_OneStimulusPerTrial -> computePerformanceNWay_OneStimulusPerTrial -> combineContainersMat. It breaks at the last step because the input is only for 1 frame of a stimulus (i.e., dimension < 3). To fix it, we could either add temporalModulation as a varargin or replace createGratingScene with sceGrating.
	DHB: If we can make this work by special casing 2D inputs to treat them as one frame, that would be best. We think
	this problem arises because Matlab now squeezes trailing singleton dimensions of matrices, for better or worse.
	FH: this bug has been fixed by using nrePhotopigmentExcitationsCmosaicWithNoEyeMovements.m instead of nrePhotopigmentExcitationsConeMosaicHexWithNoEyeMovements.m. I guess the former returns a 3-d matrix (#trials x #timeSamples x #cones).
	There are some other bugs in the code (e.g., in computeThresholdNWay_OneStimulusPerTrial.m, I added line 119-123). The code can run now, but it seems like it's stuck in a weird loop. More debugging is required.
	DHB: rename t_NWay_OneStimPerTrial.m -> t_NWay_OneStimulusPerTrial.m
	FH: I reduced the fovDegs, fixed some bugs in handling the quest method (e.g., lines 113 - 202). I also changed the threshold criterion for different NWay-1stimulus task, and also fixed the plot.
	DBH: put in the title (the threshold level), plot both with without criterion change; add a line at top to show what changes I did. 

============================================================================================================================
Merging
1) There are a lot of versions of different nre's that use the cMosaic.  Rationalize.  Perhaps all the specific ones should be implemented as calls into the most general one?

nrePhotopigmentExcitationsCmosaicWithNoEyeMovements.m: why do we need to compute the OIsequence at all time samples even though only the oi of the first frame is used (line 209-250)? Size of theNeuralResponses(noiseFlags{idx}) = #trials x #timeSamples x #cones

nrePhotopigmentExcitationsCmosaic.m: Size of theNeuralResponses(noiseFlags{idx}) = #trials x #timeSamples x #cones. All the oiSequence is passed into theConeMosaic.compute function unlike the function above. nrePhotopigmentExcitationsCmosaicWithNoEyeMovements.m is more like a special case, and it's suitable when the optical image does not differ across all time samples. 

nrePhotopigmentExcitationsSingleShot.m: Size of theNeuralResponses(noiseFlags{idx}) = #trials x 1 x #cones. This can totally be replaced by nrePhotopigmentExcitationsCmosaic.m without even specifying there is only one frame.

DHB: change the comments in nrePhotopigmentExcitationsCmosaicSingleShot.m, nrePhotopigmentExcitationsCmosaicWithNoEyeMovements.m to describe what they do, and to indicate that they are special cases of nrePhotopigmentExcitationsCmosaic.m; keep the first two functions, but when called, direct to nrePhotopigmentExcitationsCmosaic.m (backward compatibility) and +error message ('this is a better way to call the function ... ). Add a check that the oiSequence satisfies that either it has one frame or all the frames are the same (oiGet(oi, 'photons') returns 3d matrix).  

FH: I had to change one of the properties ('neuralComputeFunction') in the neuralResponseEngine.m, otherwise I couldn't make the switch to nrePhotopigmentExcitationsCmosaic.m if the other two functions are called. 
Validation: 
I tested calling ...SingleShot.m & ...WithNoEyeMovements.m and then either sticking with the deprecated function (responded 'no') or switching to ...Cmosaic.m. I compared the measured contrast sensitivities for several spatial frequencies. They matched.

DHB: Key value pair in the general routine; e.g., 'useFirstScene', 'amputate nre... CmosaicWithNoEyements', false: doesn't amputate; keep the warning... ; get rid of all the old code after line 195. Move all the checking code (whether frames are the same to the new function). line 181, scale the difference (consider if the mean is 0, then don't even bother to divide). Delete comments in those two old functions, refer comments in the general new function.

FH: did all the above. NEED TO TEST IF THE BEHAVIOR OF nrePhotopigmentExcitationsCmosaic.m is the same as nrePhotopigmentExcitationsCmosaicWithNoEyeMovements.m if 'amputateScenes' is set to true. 


2) Similarly, we need to think about whether we need both TAFC versions of various stuff and the NWay_OneStimulusPerTrial.  Can we make the TAFC versions calls into the NWay_OneSTimulusPerTrial?

computeThresholdNWay_OneStimulusPerTrial.m: use Quest to find test contrast values
	inputs: theTestSceneSquences (type: cell, size: [1 x #A]; each cell has a size of [1 x #times]; each cell is a struct)
	-> computePerformanceNWay_OneStimulusPerTrial.m: training & making predictions
		-> rcePoissonNWay_OneStimulusPerTrial.m: training, to compute the templates for different alternatives
			inputs: inSampleStimResponses (type: container, size: 1 x 1, key: 'none'; it has [1 x #A] cells, each cell is [#trials x #times x #cones]) 
			outputs: theClassifierEngine.preProcessingConstants.theTemplates (type: cell, size: 1 x #A; each cell is [1 x (#times x #cones)])
		-> rcePoissonNWay_OneStimulusPerTrial.m: making predictions
			inputs: outOfSampleStimResponses (type: container, size: 1 x 1; key: 'random'; the container has a matrix [#testTrials x (#times x #cones)])
			        theClassifierEngine.preProcessingConstants.theTemplates 
			-> PoissonDecisionLogLikelihoood.m: computing log likelihood of each template for the test and alternatives given the responses
			outputs: predictions (type: vector, size: #trials)
	outputs: predictions, theClassifierEngine

computeThresholdTAFC.m
	inputs: theNullSceneSequence (type: cell, size: 1 x #Times; each cell is a struct)
	        theTestSceneSequences 
	-> computePerformanceTAFC.m: training & making predictions
		-> rcePoissonTAFC.m: training, to compute the templates for the null and the test stimuli
			inputs: inSampleNullStimResponses (type: container, size: 1 x 1, key = 'none'; each container has a matrix [1 x #times x #cones]
			        inSampleTestStimResponses
			outputs: theClassifierEngine.preProcessingConstants.nullTemplate (type: mat, size: [1 x (#times x #cones)]]
				 theClassifierEngine.preProcessingConstants.testTemplate 
		-> rcePoissonTAFC.m: making predictions
			inputs: outOfSampleNullStimResponses (type: container, size: 1 x 1, key = 'random'; the container has a matrix [#testTrials x (#times x #cones)]
			        outOfSampleTestStimResponses 
			        theClassifierEngine.preProcessingConstants.nullTemplate
			        theClassifierEngine.preProcessingConstants.testTemplate
			-> PoissonDecisionLogLikelihoood.m: computing log likelihood of test/null template given test/null responses, and vice versa 
			outputs: predictions (type: vector, size: #trials)
	outputs: predictions, theClassifierEngine


Merging the two: 
computeThreshold.m: it has one more varargin key/value pair compared to computeThresholdNWay_OneStimulusPerTrial.m & computeThresholdTAFC.m
	(line 69, 160) varargin: 'TAFC', default: false
	(line 195) inputs: theSceneSequences (type: cell, size: [1 x #A] or [1 x 2]; each cell has a size of [1 x #times]; each cell is a struct)
	-> (line 280) computePerformance.m: training & making predictions
		-> rcePoisson.m (almost the same as rcePoissonNWay_OneStimulusPerTrial.m): training, to compute the templates for different scenes
			inputs: inSampleStimResponses 
					'TAFC', true: (type: container, size: 1 x 1, key: 'none'; it has [1 x 2] cells, 1st: test, 2nd: null, each cell is [#trials x #times x (#cones x 2)])
					'TAFC', false: (type: container, size: 1 x 1, key: 'none'; it has [1 x #A] cells, each cell is [#trials x #times x #cones]) 
			outputs: theClassifierEngine.preProcessingConstants.theTemplates
					'TAFC', true: (type: cell, size: 1 x #A; each cell is [1 x (#times x (#cones x 2))])
					'TAFC', false: (type: cell, size: 1 x #A; each cell is [1 x (#times x #cones)])
		-> rcePoisson.m (almost the same as rcePoissonNWay_OneStimulusPerTrial.m): making predictions
			inputs: outOfSampleStimResponses 
					'TAFC', true: (type: container, size: 1 x 1; key: 'random'; the container has a matrix [#testTrials x (#times x (#cones x 2))])
					'TAFC', false: (type: container, size: 1 x 1; key: 'random'; the container has a matrix [#testTrials x (#times x #cones)])
				theClassifierEngine.preProcessingConstants.theTemplates 
				whichAlternatives (labels for the correct templates)
			-> PoissonDecisionLogLikelihoood.m: computing log likelihood of correct vs. incorrect
			outputs: predictions (type: vector, size: #trials)
	outputs: predictions, theClassifierEngine
DHB: make a key value pair ('TAFC': false'), delete rcePoissonTAFC.m and stuff 
FH: Validation: 
(a) Run t_NWay_OneStimulusPerTrial.m using {computeThresholdNWay_OneStimulusPerTrial.m, computePerformanceNWay_OneStimulusPerTrial.m, rcePoissonNWay_OneStimulusPerTrial.m}, given a single-frame scene and enough trials per contrast level, compared to the results simulated by {computeThreshold.m, computePerformance.m, rcePoisson.m}. The simulated sensitivities match closely (logThreshold = [-1.58, -1.46, -1.35. -1.22], = [-1.55, -1.43, -1.35, -1.24]). 
(b) Repeat (a) but the stimuli now have 2 frames. The stimulated sensitivities do match (logThreshold = [-1.72, 1.62, 1.47, 1.37], = [-1.74, 1.61, 1.49, 1.39]). 
(c) Run t_spatialCSF.m using {computeThresholdTAFC.m, computePerformanceTAFC.m, rcePoissonTAFC.m}, given a single-frame scene and enough trials for Quest, compared to the results simulated by {computeThreshold.m, computePerformance.m, rcePoisson.m}. The simulated sensitivities match closely (logThreshold = [-1.07, -0.86, -0.52, -0.00], = [-1.08, -0.86, -0.56, -0.00]). 
(d) Repeat (c) but the stimuli now have 2 frames. The stimulated sensitivities do match closely (logThreshold = [-1.23, -0.97, -0.70, -0.10], = [-1.25, -0.95, -0.69, -0.09])

Edited and moved computeThreshold_OneStimulusPerTrial.m & computeThresholdTAFC.m, and validated by testing the cleaned up versions.
Edited and moved computePerformance_OneStimulusPerTrial.m & computePerformanceTAFC.m and validated by running t_thresholdEngine.m

============================================================================================================================
Answered questions
1) When I call nrePhotopigmentsExcitationsCMosaicWithNoEyeMovements.m, I got a Warning: "The optical image resolution (4.20 microns) is too low relative to the cone aperture (3.36 microns) for accurate computation of cone blur. Skipping blur by cone aperture. Consider increasing the # of pixels in the stimulus or decrease the stimulus FOV." What is a reasonable value for # of pixels? 
	DHB: reduce the field of view instead of increase #pixels. Add a comment explaining the choice of small field of view is just for the purpose of this tutorial, and they have other options.

2) I thought that there is only one classifier that segregates the responses to all null stimuli and the responses to all test stimuli, but I think this understanding is not correct. Based on the code, there is one classifier for every level of contrast. Should there be N classifiers where N denotes the number of contrast, or just one single classifier?
	DHB: Neither is wrong but they make different assumptions about the observer.






